# Курс Байесовские методы анализа данных, ФТиАД 2019

### Где и когда
Занятия проходят по понедельникам, 18:10 — 21:00, ауд. R505 (Покровский бульвар, 11).

### Ссылки
Чат в telegram: https://t.me/joinchat/DEBCqhcF1VFBC5qnQGfdVg

[Anytask курса](https://anytask.org/course/556) (инвайт в чате)

### Правила выставления оценок
В курсе предусмотрено несколько форм контроля знания:
* Домашние работы (на Python/NumPy и теоретические)
* Экзамен

Итоговая оценка вычисляется на основе оценки за работу в семестре и оценки за экзамен:

O<sub>итоговая</sub> = 0.7 * О<sub>накопленная</sub> + 0.3 * О<sub>экз</sub>

O<sub>накопленная</sub> = О<sub>домашние задания</sub>

Оценка за домашнюю работу вычисляется как среднее по домашним заданиям.

Накопленная, экзаменационная и итоговая оценки округляются арифметически.

### Экзамен
[Вопросы к экзамену (прошлогодняя версия)](https://github.com/ftad/BM2018/blob/master/materials/BMMO_exam.pdf)

Экзамен письменный, экзаменационная работа состоит из теоретических вопросов из списка вопросов и задач. Продолжительность написания: 1 час 30 минут. На экзамене нельзя ничем пользоваться.

Во время экзамена на проекторе или доске будут отображаться некоторые формулы (список в начале списка вопросов).

### Правила сдачи домашних заданий

Дедлайн по заданиям — начало следующего занятия (жесткий).

Два раза за курс дедлайн можно просрочить, в этом случае за каждый день просрочки будет начисляться штраф -1 балл.

При обнаружении плагиата оценки за домашнее задание обнуляются всем задействованным в списывании студентам. Это очень строгое правило!

### Материалы занятий
__На канале ФКН на Youtube доступны [видео](https://www.youtube.com/watch?v=Ejsr3S79gcQ&list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw) лекций Ветрова Д. П.__

__Занятие 1. Байесовские рассуждения__
* [Видео лекции](https://www.youtube.com/playlist?list=PLEqoHzpnmTfCiJpMPccTWXD9DB4ERQkyw)
* [Конспект лекции](https://drive.google.com/file/d/13Q58mRGh5uN8xyhMiTfoOXOYvxUKbvRY/view)
* [Еще один конспект](http://www.machinelearning.ru/wiki/images/8/8c/Lecture7_2012.pdf)
* [Задачи семинара](http://www.machinelearning.ru/wiki/images/1/18/S01_bayesian_reasoning_2016.pdf)

__Занятие 2. Сопряженные распределения и принцип наибольшей обоснованности__
* [Конспект-презентация про сопряженные распределения](http://www.machinelearning.ru/wiki/images/b/bd/BMMO11_5.pdf)
* [Конспект-презентация про обоснованность](http://www.machinelearning.ru/wiki/images/b/bd/BMMO11_5.pdf)
* [Мини-конспект про сопряженные распределения](https://drive.google.com/file/d/1g9cNLw85MchawKbSV7F0nUXyEi9m36sR/view)
* [Мини-конспект про обоснованность](https://drive.google.com/file/d/1l8fhZQ5V60wZaL9n_YlKNESW1y01PtX2/view?usp=sharing)
* [Презентация с распределениями](https://github.com/ftad/BM2018/blob/master/materials/distributions.pdf) 

__Занятие 3. Экспоненциальный класс распределений и матричное дифференцирование__
* [Конспект о матричном дифференцировании](http://www.machinelearning.ru/wiki/images/1/16/S04_matrix_calculations.pdf)
* [Об экспоненциальном классе](https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter8.pdf) от Michael I. Jordan
* [Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)

__Занятие 4. Метод релевантных векторов__
* [Конспект-презентация](http://www.machinelearning.ru/wiki/images/d/d0/BMMO11_7.pdf)

__Занятие 5. EM-алгоритм__
* [Презентация по EM-алгоритму](https://drive.google.com/file/d/1CFGIuArumNz-qjVdCQqlxSpRbgGG3Ij_/view?usp=sharing)

__Занятие 6. EM-алгоритм. Решение задач__
* [Презентация по задаче с восстановлением фото](https://github.com/ftad/BM2018/blob/master/homeworks/homework6_theory.pdf)
* [Байесовский метод главных компонент](http://www.machinelearning.ru/wiki/images/7/73/BMMO11_11.pdf)

__Занятие 7. EM-алгоритм. Вариационный вывод__
* [Конспект с примерами применения](http://www.machinelearning.ru/wiki/images/3/34/Variational_inference.pdf)
* [Решение задачи](https://drive.google.com/file/d/0B7TWwiIrcJstTEpMUkRSTEk0VDA/view)
* Теория с пояснениями - 21 chapter, Murphy K.P. Machine Learning: A Probabilistic Perspective.

__Занятие 8. Байесовские нейронные сети__
* [Презентация](https://github.com/ftad/BM2019/blob/master/materials/hw7/BNN.pdf)
* Статьи: [VarDrop & LRT](https://arxiv.org/pdf/1506.02557.pdf), [SparseVD](https://arxiv.org/pdf/1701.05369.pdf), [BinDrop as BayesianNN](https://arxiv.org/pdf/1512.05287.pdf), [ARD for NNs](https://arxiv.org/pdf/1811.00596.pdf)

__Занятие 9. Вариационные автокодировщики__
* [Презентация](https://drive.google.com/file/d/1NqtMy7uMti9Xrsck9WIqvv8o3PWP1jS4/view?usp=sharing)

__Занятие 10. Методы Монте-Карло с марковскими цепями__
* [Конспект](http://www.machinelearning.ru/wiki/images/6/6b/BMMO11_10.pdf)
* [Подробный туториал на английском](https://www.cs.ubc.ca/~arnaud/andrieu_defreitas_doucet_jordan_intromontecarlomachinelearning.pdf)

__Занятие 11. Гауссовские процессы__
* [Презентация Е. Бурнаева](https://drive.google.com/file/d/1yhSOkV2TNCSrjbrNMUtYerXXZY1dQpo4/view?usp=sharing)
* [Презентация М. Филиппоне](https://drive.google.com/file/d/0B2zoFVYw1rN3SDJ0OU1nNVRxVWc/view?usp=sharing)

__Занятие 12. Модицификации вариационных автокодироващиков__


### Задания
* [Домашнее задание 1](https://github.com/ftad/BM2018/blob/master/homeworks/homework1.pdf). Дедлайн: 18:00 16.09.19.
* [Домашнее задание 2](https://github.com/ftad/BM2019/blob/master/materials/homework2%202019.pdf). Дедлайн: 18:00 23.09.19.
* [Домашнее задание 3](https://github.com/ftad/BM2019/blob/master/materials/homework3%202019.pdf). Дедлайн: 18:00 01.10.19.
* [Домашнее задание 4](https://github.com/ftad/BM2018/blob/master/homeworks/homework4.ipynb) Дедлайн: 18:00 07.10.18. Обратите внимание, что в задании вектор правильных ответов обозначается t, а не y. Вы можете добавить аргументы в прототипы функций, если вам это нужно. Алгоритм приведен [в презентации](http://www.machinelearning.ru/wiki/images/d/d0/BMMO11_7.pdf) на слайде 17.
* [Домашнее задание 5](https://github.com/ftad/BM2018/blob/master/homeworks/homework5.pdf) Дедлайн: 18:00 14.10.18
* [Домашнее задание 6.](https://github.com/ftad/BM2019/blob/master/materials/homework6.ipynb) [Данные.](https://github.com/ftad/BM2019/blob/master/materials/data_hw6.zip) Дедлайн: 23:59 03.11.2019.
* [Домашнее задание 7.](https://github.com/ftad/BM2019/tree/master/materials/hw7) (скачайте hw7.ipynb и logger.py). Дедлайн: 23:59 19.11.2019.
* [Домашнее задание 8.](https://github.com/ftad/BM2019/blob/master/materials/homework_MCMC.pdf). Дедлайн: 23:59 05.12.2019.
* [Домашнее задание 9.](https://github.com/ftad/BM2019/blob/master/materials/homework10_opt.ipynb) - необязательное. Дедлайн: 23:59 25.12.2019 


### Полезные материалы
Книги:
* Barber D. [Bayesian Reasoning and Machine Learning.](http://www0.cs.ucl.ac.uk/staff/d.barber/brml/) Cambridge University Press, 2012.
* Murphy K.P. Machine Learning: A Probabilistic Perspective. The MIT Press, 2012.
* Bishop C.M. [Pattern Recognition and Machine Learning.](http://research.microsoft.com/en-us/um/people/cmbishop/prml/) Springer, 2006. 
* Mackay D.J.C. [Information Theory, Inference, and Learning Algorithms.](http://www.inference.phy.cam.ac.uk/mackay/itila/book.html) Cambridge University Press, 2003. 
* Tipping M. [Sparse Bayesian Learning.](http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf) Journal of Machine Learning Research, 1, 2001, pp. 211-244. 
* Шумский С.А. [Байесова регуляризация обучения.](http://www.niisi.ru/iont/ni/Library/School-2002/Shumsky-2002.pdf) В сб. Лекции по нейроинформатике, часть 2, 2002.

Простые и удобные [заметки](http://cs.nyu.edu/~roweis/notes.html) по матричным вычислениям и свойствам гауссовских распределений.

[Памятка](http://statistics.zone/) по теории вероятностей.
